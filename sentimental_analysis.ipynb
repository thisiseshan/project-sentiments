{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentimental-analysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddCUEK0FsFVT",
        "colab_type": "text"
      },
      "source": [
        "#Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csGQKot6sEBn",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "am92fyz8sPwq",
        "colab_type": "text"
      },
      "source": [
        "###Importing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1shm9z9tsRoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmDBBQduo37b",
        "colab_type": "text"
      },
      "source": [
        "###Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOqBhTQwn85R",
        "colab_type": "code",
        "outputId": "c676aa57-a9f8-40f1-fa86-46b464e3e123",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# !unzip archive.zip\n",
        "# %cd archive\n",
        "#%cd data\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/archive/data/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpZshfuoqKjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "positive_counter = Counter()\n",
        "negative_counter = Counter()\n",
        "total_counts = Counter()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtLULdSOCeGU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "outputId": "1191fb1e-2b43-461c-a470-448b7dfe3168"
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdata\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89mQtoicuXD9",
        "colab_type": "text"
      },
      "source": [
        "##Curating Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6bnAQkzsB2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_review_and_label(i):\n",
        "  print(labels[i] + \"\\t:\\t\" + reviews[i][:80] + \"...\")\n",
        "  \n",
        "g = open('reviews.txt','r')\n",
        "reviews = list(map(lambda x:x[:-1], g.readlines()))\n",
        "g.close()\n",
        "\n",
        "g = open('labels.txt','r')\n",
        "labels = list(map(lambda x:x[:-1], g.readlines()))\n",
        "g.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyjurZePuwm9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print_review_and_label(1)\n",
        "print_review_and_label(2)\n",
        "print_review_and_label(3)\n",
        "print_review_and_label(4)\n",
        "print_review_and_label(5)\n",
        "print_review_and_label(6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFCI8Fq3pJ7z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(reviews)):\n",
        "  if(labels[i] == 'positive'):\n",
        "    for word in reviews[i].split(\" \"):\n",
        "      positive_counter[word] += 1\n",
        "      total_counts[word] += 1\n",
        "  else:\n",
        "    for word in reviews[i].split(\" \"):\n",
        "      negative_counter[word] += 1\n",
        "      total_counts[word] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnOOzr59xmm7",
        "colab_type": "text"
      },
      "source": [
        "##Create Input/Output Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwkHRYOerxFw",
        "colab_type": "code",
        "outputId": "a7f5f8b6-0186-46ea-ad68-353c60ea6169",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab = set(total_counts.keys())\n",
        "vocab_size = len(vocab)\n",
        "print(vocab_size)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "74074\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzmRXag3xzhD",
        "colab_type": "code",
        "outputId": "2bfba896-00a6-401a-acb2-6974b4855a02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "layer_0 = np.zeros((1,vocab_size))\n",
        "layer_0"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGiFBKMcyBi2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word2index = {}\n",
        "\n",
        "for i,word in enumerate(vocab):\n",
        "  word2index[word] = i\n",
        "\n",
        "\n",
        "word2index\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-huUtNsszFHf",
        "colab_type": "code",
        "outputId": "5fa92499-87c7-48ff-9790-6a1ef7c102e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "layer_0.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 74074)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CD2JzUXBKwPn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b3b490ba-ee22-4bd1-e2f0-20e563603cb2"
      },
      "source": [
        "labels[1]"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'negative'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXzMhD1Nz9sx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_input_layer(review):\n",
        "  \n",
        "  global layer_0\n",
        "  \n",
        "  #clear out all previous state, reset the layer to all 0s\n",
        "  layer_0 *= 0\n",
        "  for word in review.split(\" \"):\n",
        "    layer_0[0][word2index[word]] += 1\n",
        "    \n",
        "update_input_layer(reviews[0])    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iT0dk8iEDRe5",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ATnUR2R27Ob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_target_for_label(label):\n",
        "  if(label == 'positive'):\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBP9V68D300w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(0,100):\n",
        "  print(get_target_for_label(labels[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dZc-32CMJ2X",
        "colab_type": "text"
      },
      "source": [
        "##Create Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8JCRXI5374J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1VI6h2TMNo1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class neuralnet(nn.Module):\n",
        "  \n",
        "  \n",
        "  def __init__(self,input_dim,hidden_dim,output_dim):\n",
        "    super(neuralnet, self).__init__()\n",
        "    \n",
        "    # Assign a seed to our random number generator to ensure we get reproducable results during development\n",
        "    np.random.seed(1)\n",
        "    \n",
        "    # process the reviews and their associated labels so that everything is ready for training\n",
        "    self.pre_process_data(reviews, labels)\n",
        "    \n",
        "    # Build the network to have the number of hidden nodes and the learning rate that were passed into this initializer. Make the same number of input nodes as\n",
        "    # there are vocabulary words and create a single output node.\n",
        "      self.init_network(len(self.review_vocab),hidden_nodes, 1, learning_rate)\n",
        "    \n",
        "    # Linear Function\n",
        "    self.f1 = nn.Linear(input_dim, hidden_dim)\n",
        "    \n",
        "    # Non-Linear Function\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "    # Linear Function (readout)\n",
        "    self.f2 = nn.Linear(hidden_dim, output_dim)\n",
        "    \n",
        "  \n",
        "    \n",
        "  def pre_process_data(self, reviews, labels):\n",
        "    \n",
        "    review_vocab = set()            # set does not contain dupliactes\n",
        "    for review in reviews:\n",
        "      for word in reviews.split(\" \"):\n",
        "        review_vocab.add(word)\n",
        "    self.review_vocab = list(review_vocab)       # coverting to list for easy iteration\n",
        "    \n",
        "    \n",
        "    label_vocab = set()\n",
        "    for label i labels:\n",
        "      label_vocab.add(label)\n",
        "    self.label_vocab = list(label_vocab)\n",
        "    \n",
        "   \n",
        "    self.review_vocab_size = len(review_vocab)\n",
        "    self.review_vocab_size = len(label_vocab)\n",
        "\n",
        "    self.word2index = {}\n",
        "    for i, word in enumerate(self.review_vocab):       # enumerate allows us to loop over something and have an automatic counter.\n",
        "      self.word2index[word] = i\n",
        "\n",
        "    self.word2index = {}\n",
        "    for i, label in enumerate(self.label_vocab):       # enumerate allows us to loop over something and have an automatic counter.\n",
        "      self.word2index[word] = i\n",
        "      \n",
        "      \n",
        "      \n",
        "      \n",
        "  def init_network(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
        "    # Set values\n",
        "    self.input_nodes = review_vocab_size\n",
        "    self.hidden_nodes = hidden_nodes\n",
        "    self.output_nodes = review_vocab_size\n",
        "      \n",
        "    # Set learning rate\n",
        "    self.learning_rate = learning_rate\n",
        "    \n",
        "    # Initialize weights\n",
        "    \n",
        "    # Weights between input layer and hidden layer\n",
        "    self.weights_0_1 = np.zeros((self.input_nodes, self.hidden_nodes))\n",
        "    \n",
        "    # Weights between hidden layer and output layer\n",
        "    self.weights_1_2 = np.random.normal(0.0, self.output_nodes**-0.5, (self.hidden_nodes, self.output_nodes))   # syntax  numpy.random.normal(loc=0.0, scale=1.0, size=None)\n",
        "    \n",
        "    # The input layer, 2 fim matrix, 1 x hidden inputs\n",
        "    self.layer_1 = np.zeros((1, hidden_nodes)\n",
        "                            \n",
        "                            \n",
        "  def sigmoid(self,x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "                 \n",
        "  def sigmoid_output_2_derivative(self,output):\n",
        "    return output * (1 - output)                        \n",
        "      \n",
        "                            \n",
        "  def get_target_for_label(label):\n",
        "    if(label == 'positive'):\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "  \n",
        "  def train(self, trainig_reviews_raw, training_labels):\n",
        "    training_reviews = list()\n",
        "    for review in training_reviews_raw:\n",
        "      indices = set()\n",
        "            for word in review.split(\" \"):\n",
        "                if(word in self.word2index.keys()):\n",
        "                    indices.add(self.word2index[word])\n",
        "            training_reviews.append(list(indices))\n",
        "    \n",
        "   \n",
        "                  \n",
        "                            \n",
        "    \n",
        "  \n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}